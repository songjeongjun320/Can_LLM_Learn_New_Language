{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server connected\n",
      "Ollama is running\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "# Extract the circumstance from the image\n",
    "################################################\n",
    "\n",
    "import requests\n",
    "import ollama\n",
    "# Ollama 서버 설정\n",
    "ollama_host = \"http://sg027:11434\"\n",
    "client = ollama.Client(host=ollama_host)  # 클라이언트 인스턴스 생성\n",
    "prompt = \"Analyze the given image and describe the specific actions and interactions of the people in this circumstance.\\\n",
    "Focus on what they are doing, their gestures, expressions, and interactions, and provide general details about the environment or objects. \\\n",
    "Guess what kind of conversation might typically occur in this situation. Ignore any information about text.\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(ollama_host)\n",
    "    print(\"Server connected\")\n",
    "    print(response.text)\n",
    "    \n",
    "except requests.ConnectionError:\n",
    "    print(\"Not connected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this serene image, a couple is situated within a cozy living room or studio apartment. The woman stands at the edge of an orange couch with a white blanket draped over it, while the man stands by the sliding glass door on the right side of the picture.\n",
      "\n",
      "On the left wall, two chairs are positioned in front of a wooden table and a large, modern TV is mounted against the wall. A small coffee table sits between the sofa and the woman's feet, creating a comfortable seating area. The beige carpet adds warmth to the space. Outside the glass door, tall buildings can be seen through the sheer white curtains.\n",
      "\n",
      "The overall atmosphere suggests that this couple may be enjoying some quality time together, possibly relaxing or watching TV in their home.\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "# Test llama vision working\n",
    "# Must choose a100:2, for llama3.2-vision:90b\n",
    "# a100:1 works for llama3.2-vision\n",
    "################################################\n",
    "\n",
    "import base64\n",
    "\n",
    "with open(\"./Data_Images/고물가시대 혜자로운 코스트코 장보기/frame_0009.png\", \"rb\") as img_file:\n",
    "    base64_image = base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "    \n",
    "response = client.chat(\n",
    "    model='llama3.2-vision', # need a100:1 gpu\n",
    "    # model='llama3.2-vision:90b', # need a100:2 gpu\n",
    "    messages=[{\n",
    "        'role': 'user',\n",
    "        'content': prompt,\n",
    "        'images': [base64_image]  # Base64 문자열 전달\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows a couple standing by an open balcony door in a modern apartment.\n",
      "\n",
      "In the foreground, on the right side of the image, the woman is wearing a light green dress and has her hands outstretched towards the balcony. The man is to her left, wearing a dark t-shirt. \n",
      "\n",
      "To their left are two chairs and a small table with a bottle of champagne and glasses. In front of them is a large TV screen on a wall-mounted stand.\n",
      "\n",
      "The background features a city skyline at night, with tall buildings and bright lights visible through the open balcony door. \n",
      "\n",
      "Overall, the image suggests that the couple is celebrating a special occasion or enjoying some time together in their luxurious apartment.\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "# Test llama vision working\n",
    "# Must choose a100:2, for llama3.2-vision:90b\n",
    "# a100:1 works for llama3.2-vision\n",
    "################################################\n",
    "response = client.chat(\n",
    "    # model='llama3.2-vision', # need a100:1 gpu\n",
    "    model='llama3.2-vision:90b', # need a100:2 gpu\n",
    "    messages=[{\n",
    "        'role': 'user',\n",
    "        'content': prompt,\n",
    "        'images': [base64_image]  # Base64 문자열 전달\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "# Check all the images in one drama folder\n",
    "# Read and analyze through llama3.2-vision\n",
    "#######################\n",
    "\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "import ollama\n",
    "import time\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def process(base_path, drama_folder_name, version):\n",
    "    # 경로 설정\n",
    "    base_path = base_path\n",
    "    drama_folder_name = drama_folder_name\n",
    "    version = version\n",
    "    \n",
    "    image_dir = Path(f'{base_path}/Data_Images/{drama_folder_name}')\n",
    "    output_file = Path(f'{base_path}/Refined_Datas/{version}/Data_llama_vision/{drama_folder_name}.json')\n",
    "    \n",
    "    #######################\n",
    "    # model choose\n",
    "    #######################\n",
    "    used_model = \"llama3.2-vision\"\n",
    "    \n",
    "    # 출력 디렉토리 생성\n",
    "    output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 로깅 설정\n",
    "    def log(message, level=\"INFO\"):\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(f\"[{timestamp}] [{level}] {message}\")\n",
    "    \n",
    "    # 초기화\n",
    "    results = []\n",
    "    VALID_EXTENSIONS = ('.png', '.jpg', '.jpeg')\n",
    "    total_images = len([f for f in image_dir.iterdir() if f.suffix.lower() in VALID_EXTENSIONS])\n",
    "    processed = 0\n",
    "    \n",
    "    log(f\"Starting image processing for {total_images} images\")\n",
    "    \n",
    "    # 이미지 처리\n",
    "    for image_path in image_dir.iterdir():\n",
    "        if not (image_path.is_file() and image_path.suffix.lower() in VALID_EXTENSIONS):\n",
    "            continue\n",
    "    \n",
    "        processed += 1\n",
    "        log(f\"Processing image ({processed}/{total_images}): {image_path.name}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # 이미지 인코딩\n",
    "            encode_start = time.time()\n",
    "            with open(image_path, \"rb\") as img_file:\n",
    "                base64_image = base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "            encode_time = time.time() - encode_start\n",
    "            log(f\"Image encoded in {encode_time:.2f}s\")\n",
    "    \n",
    "            # API 요청\n",
    "            api_start = time.time()\n",
    "            used_model = \"llama3.2-vision\"\n",
    "            response = client.chat(\n",
    "            ###################### Choose Model ###################\n",
    "                model=\"llama3.2-vision\",\n",
    "                # \"llama3.2-vision:90b\"\n",
    "                # llama3.2-vision\"\n",
    "                messages=[{\n",
    "                    'role': 'user',\n",
    "                    'content': prompt,\n",
    "                    'images': [base64_image]\n",
    "                }]\n",
    "            )\n",
    "            api_time = time.time() - api_start\n",
    "            log(f\"API response received in {api_time:.2f}s\")\n",
    "    \n",
    "            # 결과 저장\n",
    "            results.append({\n",
    "                'image': str(image_path),\n",
    "                'response': response['message']['content'],\n",
    "                'processing_time': {\n",
    "                    'encoding': encode_time,\n",
    "                    'api_call': api_time,\n",
    "                    'total': time.time() - start_time\n",
    "                },\n",
    "                'status': 'success'\n",
    "            })\n",
    "    \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error processing {image_path.name}: {str(e)}\"\n",
    "            error_trace = traceback.format_exc()\n",
    "            log(error_msg, \"ERROR\")\n",
    "            log(f\"Error details:\\n{error_trace}\", \"DEBUG\")\n",
    "            \n",
    "            results.append({\n",
    "                'image': str(image_path),\n",
    "                'error': error_msg,\n",
    "                'error_trace': error_trace,\n",
    "                'status': 'failed'\n",
    "            })\n",
    "    \n",
    "    # 결과 저장\n",
    "    save_start = time.time()\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=4)\n",
    "    save_time = time.time() - save_start\n",
    "    \n",
    "    log(\"=========================================\")\n",
    "    log(f\"Results saved to {output_file} in {save_time:.2f}s\")\n",
    "    log(f\"Processing completed. Success: {len([x for x in results if x['status']=='success'])}, Failed: {len([x for x in results if x['status']=='failed'])}\")\n",
    "    log(\"=========================================\")\n",
    "    \n",
    "    #######################\n",
    "    # Organize by frame number\n",
    "    #######################\n",
    "    \n",
    "    # 파일 경로 설정\n",
    "    input_file = Path(f'{base_path}/Refined_Datas/{version}/Data_llama_vision/{drama_folder_name}.json')\n",
    "    output_file = Path(f'{base_path}/Refined_Datas/{version}/Data_llama_vision/{drama_folder_name}_organized.json')\n",
    "    \n",
    "    # JSON 파일 읽기\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # 아이템 처리 함수\n",
    "    def process_item(item):\n",
    "        try:\n",
    "            filename = Path(item['image']).name\n",
    "            \n",
    "            # 파일명 구조: frame_0001.png → ['frame', '0001.png']\n",
    "            parts = filename.split('_')\n",
    "            \n",
    "            # 숫자 부분 추출 (frame_0001.png → 0001)\n",
    "            frame_number = int(parts[1].split('.')[0])  # frame_0001.png → 0001\n",
    "            \n",
    "            return {\n",
    "                'image': filename,\n",
    "                'frame_number': frame_number,\n",
    "                'response': item['response'],\n",
    "                'status': item['status']\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"파일명 형식 오류: {filename} → {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    # 데이터 처리 (오류 항목 필터링)\n",
    "    processed_data = [item for item in (process_item(i) for i in data) if item is not None]\n",
    "    \n",
    "    # 숫자 순으로 정렬 (frame_number 기준)\n",
    "    sorted_data = sorted(processed_data, key=lambda x: x['frame_number'])\n",
    "    \n",
    "    # 최종 출력 형식\n",
    "    final_data = [\n",
    "        {\n",
    "            'used_model': 'llama3.2-vision',  # 모델 이름을 하드코딩 (필요 시 수정)\n",
    "            'image': sorted_data[0]['image'],\n",
    "            'response': sorted_data[0]['response'],\n",
    "        }\n",
    "    ] + [\n",
    "        {\n",
    "            'image': item['image'],\n",
    "            'response': item['response'],\n",
    "        }\n",
    "        for item in sorted_data[1:]\n",
    "    ]\n",
    "    \n",
    "    # JSON 파일로 저장\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(final_data, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "    # 파일 삭제\n",
    "    if input_file.exists():  # 파일이 존재하는지 확인\n",
    "        input_file.unlink()  # 파일 삭제\n",
    "        print(f\"파일 제거: {input_file}\")\n",
    "    else:\n",
    "        print(f\"{input_file} 파일이 존재하지 않습니다.\")\n",
    "        \n",
    "    print(f\"정렬 완료! 결과 파일: {output_file}\")\n",
    "    \n",
    "    ################################################\n",
    "    # Merging llama-vision result + subtitle + timestamp\n",
    "    ################################################\n",
    "    output_file = Path(f'{base_path}/Refined_Datas/{version}/Data_llama_vision/{drama_folder_name}_organized.json')\n",
    "    \n",
    "    # llama_vision_data.json 파일 로드\n",
    "    with open(output_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        llama_vision_data = json.load(f)\n",
    "    \n",
    "    subtitle = Path(f'{base_path}/Data_Subtitles/{drama_folder_name}_organized.ko.json')\n",
    "    # subtitle.json 파일 로드\n",
    "    with open(subtitle, \"r\", encoding=\"utf-8\") as f:\n",
    "        subtitle_data = json.load(f)\n",
    "    \n",
    "    # final_output.json으로 저장할 데이터 리스트 초기화\n",
    "    dataset = []\n",
    "    \n",
    "    # 두 파일의 데이터를 매칭하여 dataset 생성\n",
    "    for result_item, subtitle_item in zip(llama_vision_data, subtitle_data):\n",
    "        input_text = subtitle_item.get(\"context\", \"\")  # subtitle_data.json의 \"context\"를 input으로\n",
    "        timestamp = subtitle_item.get(\"timestamp\", \"\")  # subtitle_data.json의 \"timestamp\"를 timestamp\n",
    "        output_text = result_item.get(\"response\", \"\")  # llama_vision_data.json의 \"response\"를 output으로\n",
    "        \n",
    "        # input, output, timestamp가 모두 비어있지 않은 경우만 추가\n",
    "        if input_text and output_text:\n",
    "            dataset.append({\"timestamp\": timestamp, \"input\": input_text, \"output\": output_text})\n",
    "    \n",
    "    # 디렉토리가 없으면 생성\n",
    "    final_output = Path(f'{base_path}/Refined_Datas/{version}/Data_Final/')\n",
    "    final_output.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"디렉토리가 생성되었습니다: {final_output}\")\n",
    "    \n",
    "    final_output = Path(f'{base_path}/Refined_Datas/{version}/Data_Final/{drama_folder_name}_final.json')\n",
    "    # dataset.json 파일로 저장\n",
    "    with open(final_output, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(dataset, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"/Refined_Datas/{version}/Data_Final/{drama_folder_name}_final.json 파일이 생성되었습니다.\")\n",
    "    \n",
    "    ###############################################\n",
    "    # Reverse input <-> output\n",
    "    # Professor suggestion\n",
    "    ################################################\n",
    "    \n",
    "    # final_output 파일 경로 설정\n",
    "    final_output = Path(f'{base_path}/Refined_Datas/{version}/Data_Final/{drama_folder_name}_final.json')\n",
    "    \n",
    "    # final_output에서 데이터 읽기\n",
    "    with open(final_output, \"r\", encoding=\"utf-8\") as f:\n",
    "        dataset = json.load(f)\n",
    "    \n",
    "    # input과 output 값을 교환하는 작업\n",
    "    reversed_dataset = []\n",
    "    for item in dataset:\n",
    "        # input과 output을 서로 바꾸기\n",
    "        reversed_item = {\n",
    "            'timestamp': item['timestamp'],\n",
    "            'input': item['output'],  # output을 input으로\n",
    "            'output': item['input'],  # input을 output으로\n",
    "        }\n",
    "        reversed_dataset.append(reversed_item)\n",
    "    \n",
    "    # 기존 dataset과 reversed_dataset을 합치기\n",
    "    combined_dataset = dataset + reversed_dataset\n",
    "    \n",
    "    # 디렉토리가 없으면 생성\n",
    "    reversed_final_output = Path(f'{base_path}/Refined_Datas/{version}/Data_Final/')\n",
    "    reversed_final_output.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"디렉토리가 생성되었습니다: {final_output}\")\n",
    "    \n",
    "    # reversed_final_output 파일 경로 설정\n",
    "    reversed_final_output = Path(f'{base_path}/Refined_Datas/{version}/Data_Final_Reversed/{drama_folder_name}_reversed_final.json')\n",
    "    \n",
    "    # combined dataset을 새로운 JSON 파일로 저장\n",
    "    with open(reversed_final_output, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(combined_dataset, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"/Refined_Datas/{version}/Data_Final_Reversed/{drama_folder_name}_reversed_final.json 파일이 생성되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-16 23:09:40] [INFO] Starting image processing for 734 images\n",
      "[2025-03-16 23:09:40] [INFO] Processing image (1/734): frame_0506.png\n",
      "[2025-03-16 23:09:40] [INFO] Image encoded in 0.09s\n",
      "[2025-03-16 23:10:10] [INFO] API response received in 29.96s\n",
      "[2025-03-16 23:10:10] [INFO] Processing image (2/734): frame_0396.png\n",
      "[2025-03-16 23:10:10] [INFO] Image encoded in 0.07s\n",
      "[2025-03-16 23:10:14] [INFO] API response received in 3.79s\n",
      "[2025-03-16 23:10:14] [INFO] Processing image (3/734): frame_0565.png\n",
      "[2025-03-16 23:10:14] [INFO] Image encoded in 0.05s\n",
      "[2025-03-16 23:10:18] [INFO] API response received in 3.68s\n",
      "[2025-03-16 23:10:18] [INFO] Processing image (4/734): frame_0495.png\n",
      "[2025-03-16 23:10:18] [INFO] Image encoded in 0.09s\n",
      "[2025-03-16 23:10:21] [INFO] API response received in 3.30s\n",
      "[2025-03-16 23:10:21] [INFO] Processing image (5/734): frame_0264.png\n",
      "[2025-03-16 23:10:22] [INFO] Image encoded in 0.29s\n",
      "[2025-03-16 23:10:24] [INFO] API response received in 2.89s\n",
      "[2025-03-16 23:10:24] [INFO] Processing image (6/734): frame_0697.png\n",
      "[2025-03-16 23:10:24] [INFO] Image encoded in 0.06s\n",
      "[2025-03-16 23:10:29] [INFO] API response received in 5.00s\n",
      "[2025-03-16 23:10:29] [INFO] Processing image (7/734): frame_0067.png\n",
      "[2025-03-16 23:10:30] [INFO] Image encoded in 0.09s\n",
      "[2025-03-16 23:10:34] [INFO] API response received in 4.37s\n",
      "[2025-03-16 23:10:34] [INFO] Processing image (8/734): frame_0626.png\n",
      "[2025-03-16 23:10:34] [INFO] Image encoded in 0.05s\n",
      "[2025-03-16 23:10:38] [INFO] API response received in 3.67s\n",
      "[2025-03-16 23:10:38] [INFO] Processing image (9/734): frame_0276.png\n",
      "[2025-03-16 23:10:38] [INFO] Image encoded in 0.06s\n",
      "[2025-03-16 23:10:42] [INFO] API response received in 4.64s\n",
      "[2025-03-16 23:10:42] [INFO] Processing image (10/734): frame_0017.png\n",
      "[2025-03-16 23:10:42] [INFO] Image encoded in 0.02s\n",
      "[2025-03-16 23:10:46] [INFO] API response received in 3.98s\n",
      "[2025-03-16 23:10:46] [INFO] Processing image (11/734): frame_0071.png\n",
      "[2025-03-16 23:10:46] [INFO] Image encoded in 0.07s\n",
      "[2025-03-16 23:10:49] [INFO] API response received in 2.72s\n",
      "[2025-03-16 23:10:49] [INFO] Processing image (12/734): frame_0669.png\n",
      "[2025-03-16 23:10:49] [INFO] Image encoded in 0.11s\n",
      "[2025-03-16 23:10:53] [INFO] API response received in 3.78s\n",
      "[2025-03-16 23:10:53] [INFO] Processing image (13/734): frame_0711.png\n",
      "[2025-03-16 23:10:53] [INFO] Image encoded in 0.12s\n",
      "[2025-03-16 23:10:58] [INFO] API response received in 5.12s\n",
      "[2025-03-16 23:10:58] [INFO] Processing image (14/734): frame_0257.png\n",
      "[2025-03-16 23:10:58] [INFO] Image encoded in 0.03s\n",
      "[2025-03-16 23:11:03] [INFO] API response received in 4.86s\n",
      "[2025-03-16 23:11:03] [INFO] Processing image (15/734): frame_0162.png\n",
      "[2025-03-16 23:11:03] [INFO] Image encoded in 0.27s\n",
      "[2025-03-16 23:11:08] [INFO] API response received in 4.28s\n",
      "[2025-03-16 23:11:08] [INFO] Processing image (16/734): frame_0514.png\n",
      "[2025-03-16 23:11:08] [INFO] Image encoded in 0.57s\n",
      "[2025-03-16 23:11:12] [INFO] API response received in 3.75s\n",
      "[2025-03-16 23:11:12] [INFO] Processing image (17/734): frame_0287.png\n",
      "[2025-03-16 23:11:12] [INFO] Image encoded in 0.07s\n",
      "[2025-03-16 23:11:15] [INFO] API response received in 2.88s\n",
      "[2025-03-16 23:11:15] [INFO] Processing image (18/734): frame_0015.png\n",
      "[2025-03-16 23:11:15] [INFO] Image encoded in 0.13s\n",
      "[2025-03-16 23:11:19] [INFO] API response received in 3.73s\n",
      "[2025-03-16 23:11:19] [INFO] Processing image (19/734): frame_0528.png\n",
      "[2025-03-16 23:11:19] [INFO] Image encoded in 0.16s\n",
      "[2025-03-16 23:11:23] [INFO] API response received in 3.54s\n",
      "[2025-03-16 23:11:23] [INFO] Processing image (20/734): frame_0073.png\n",
      "[2025-03-16 23:11:23] [INFO] Image encoded in 0.04s\n",
      "[2025-03-16 23:11:28] [INFO] API response received in 5.09s\n",
      "[2025-03-16 23:11:28] [INFO] Processing image (21/734): frame_0302.png\n",
      "[2025-03-16 23:11:28] [INFO] Image encoded in 0.07s\n",
      "[2025-03-16 23:11:33] [INFO] API response received in 5.38s\n",
      "[2025-03-16 23:11:33] [INFO] Processing image (22/734): frame_0189.png\n",
      "[2025-03-16 23:11:33] [INFO] Image encoded in 0.10s\n",
      "[2025-03-16 23:11:37] [INFO] API response received in 3.43s\n",
      "[2025-03-16 23:11:37] [INFO] Processing image (23/734): frame_0460.png\n",
      "[2025-03-16 23:11:37] [INFO] Image encoded in 0.25s\n",
      "[2025-03-16 23:11:40] [INFO] API response received in 2.79s\n",
      "[2025-03-16 23:11:40] [INFO] Processing image (24/734): frame_0344.png\n",
      "[2025-03-16 23:11:40] [INFO] Image encoded in 0.08s\n",
      "[2025-03-16 23:11:43] [INFO] API response received in 2.78s\n",
      "[2025-03-16 23:11:43] [INFO] Processing image (25/734): frame_0395.png\n",
      "[2025-03-16 23:11:43] [INFO] Image encoded in 0.06s\n",
      "[2025-03-16 23:11:46] [INFO] API response received in 3.08s\n",
      "[2025-03-16 23:11:46] [INFO] Processing image (26/734): frame_0260.png\n",
      "[2025-03-16 23:11:46] [INFO] Image encoded in 0.08s\n",
      "[2025-03-16 23:11:50] [INFO] API response received in 3.86s\n",
      "[2025-03-16 23:11:50] [INFO] Processing image (27/734): frame_0023.png\n",
      "[2025-03-16 23:11:50] [INFO] Image encoded in 0.01s\n",
      "[2025-03-16 23:11:54] [INFO] API response received in 4.13s\n",
      "[2025-03-16 23:11:54] [INFO] Processing image (28/734): frame_0613.png\n",
      "[2025-03-16 23:11:54] [INFO] Image encoded in 0.06s\n",
      "[2025-03-16 23:11:57] [INFO] API response received in 2.99s\n",
      "[2025-03-16 23:11:57] [INFO] Processing image (29/734): frame_0505.png\n",
      "[2025-03-16 23:11:57] [INFO] Image encoded in 0.34s\n",
      "[2025-03-16 23:12:03] [INFO] API response received in 5.39s\n",
      "[2025-03-16 23:12:03] [INFO] Processing image (30/734): frame_0687.png\n",
      "[2025-03-16 23:12:03] [INFO] Image encoded in 0.02s\n",
      "[2025-03-16 23:12:07] [INFO] API response received in 4.56s\n",
      "[2025-03-16 23:12:07] [INFO] Processing image (31/734): frame_0183.png\n",
      "[2025-03-16 23:12:07] [INFO] Image encoded in 0.03s\n",
      "[2025-03-16 23:12:12] [INFO] API response received in 4.54s\n",
      "[2025-03-16 23:12:12] [INFO] Processing image (32/734): frame_0212.png\n",
      "[2025-03-16 23:12:12] [INFO] Image encoded in 0.13s\n",
      "[2025-03-16 23:12:17] [INFO] API response received in 4.93s\n",
      "[2025-03-16 23:12:17] [INFO] Processing image (33/734): frame_0233.png\n",
      "[2025-03-16 23:12:17] [INFO] Image encoded in 0.04s\n",
      "[2025-03-16 23:12:20] [INFO] API response received in 3.55s\n",
      "[2025-03-16 23:12:20] [INFO] Processing image (34/734): frame_0179.png\n",
      "[2025-03-16 23:12:21] [INFO] Image encoded in 0.12s\n",
      "[2025-03-16 23:12:25] [INFO] API response received in 4.34s\n",
      "[2025-03-16 23:12:25] [INFO] Processing image (35/734): frame_0584.png\n",
      "[2025-03-16 23:12:25] [INFO] Image encoded in 0.08s\n",
      "[2025-03-16 23:12:29] [INFO] API response received in 4.47s\n",
      "[2025-03-16 23:12:29] [INFO] Processing image (36/734): frame_0527.png\n",
      "[2025-03-16 23:12:30] [INFO] Image encoded in 0.09s\n",
      "[2025-03-16 23:12:34] [INFO] API response received in 4.18s\n",
      "[2025-03-16 23:12:34] [INFO] Processing image (37/734): frame_0646.png\n",
      "[2025-03-16 23:12:34] [INFO] Image encoded in 0.04s\n",
      "[2025-03-16 23:12:37] [INFO] API response received in 3.63s\n",
      "[2025-03-16 23:12:37] [INFO] Processing image (38/734): frame_0112.png\n",
      "[2025-03-16 23:12:37] [INFO] Image encoded in 0.02s\n",
      "[2025-03-16 23:12:40] [INFO] API response received in 2.67s\n",
      "[2025-03-16 23:12:40] [INFO] Processing image (39/734): frame_0499.png\n",
      "[2025-03-16 23:12:40] [INFO] Image encoded in 0.06s\n",
      "[2025-03-16 23:12:44] [INFO] API response received in 4.13s\n",
      "[2025-03-16 23:12:44] [INFO] Processing image (40/734): frame_0177.png\n",
      "[2025-03-16 23:12:44] [INFO] Image encoded in 0.03s\n",
      "[2025-03-16 23:12:47] [INFO] API response received in 2.92s\n",
      "[2025-03-16 23:12:47] [INFO] Processing image (41/734): frame_0567.png\n",
      "[2025-03-16 23:12:47] [INFO] Image encoded in 0.06s\n",
      "[2025-03-16 23:12:50] [INFO] API response received in 2.49s\n",
      "[2025-03-16 23:12:50] [INFO] Processing image (42/734): frame_0047.png\n",
      "[2025-03-16 23:12:50] [INFO] Image encoded in 0.02s\n",
      "[2025-03-16 23:12:55] [INFO] API response received in 4.69s\n",
      "[2025-03-16 23:12:55] [INFO] Processing image (43/734): frame_0520.png\n",
      "[2025-03-16 23:12:55] [INFO] Image encoded in 0.03s\n",
      "[2025-03-16 23:12:57] [INFO] API response received in 2.68s\n",
      "[2025-03-16 23:12:57] [INFO] Processing image (44/734): frame_0388.png\n",
      "[2025-03-16 23:12:57] [INFO] Image encoded in 0.12s\n",
      "[2025-03-16 23:13:01] [INFO] API response received in 3.67s\n",
      "[2025-03-16 23:13:01] [INFO] Processing image (45/734): frame_0214.png\n",
      "[2025-03-16 23:13:01] [INFO] Image encoded in 0.05s\n",
      "[2025-03-16 23:13:06] [INFO] API response received in 5.13s\n",
      "[2025-03-16 23:13:06] [INFO] Processing image (46/734): frame_0249.png\n",
      "[2025-03-16 23:13:06] [INFO] Image encoded in 0.11s\n",
      "[2025-03-16 23:13:11] [INFO] API response received in 4.58s\n",
      "[2025-03-16 23:13:11] [INFO] Processing image (47/734): frame_0099.png\n",
      "[2025-03-16 23:13:11] [INFO] Image encoded in 0.06s\n",
      "[2025-03-16 23:13:15] [INFO] API response received in 4.27s\n",
      "[2025-03-16 23:13:15] [INFO] Processing image (48/734): frame_0130.png\n",
      "[2025-03-16 23:13:15] [INFO] Image encoded in 0.04s\n",
      "[2025-03-16 23:13:18] [INFO] API response received in 2.73s\n",
      "[2025-03-16 23:13:18] [INFO] Processing image (49/734): frame_0539.png\n",
      "[2025-03-16 23:13:18] [INFO] Image encoded in 0.03s\n",
      "[2025-03-16 23:13:22] [INFO] API response received in 3.57s\n",
      "[2025-03-16 23:13:22] [INFO] Processing image (50/734): frame_0316.png\n",
      "[2025-03-16 23:13:22] [INFO] Image encoded in 0.03s\n",
      "[2025-03-16 23:13:25] [INFO] API response received in 2.96s\n",
      "[2025-03-16 23:13:25] [INFO] Processing image (51/734): frame_0563.png\n",
      "[2025-03-16 23:13:25] [INFO] Image encoded in 0.04s\n",
      "[2025-03-16 23:13:28] [INFO] API response received in 3.21s\n",
      "[2025-03-16 23:13:28] [INFO] Processing image (52/734): frame_0234.png\n",
      "[2025-03-16 23:13:28] [INFO] Image encoded in 0.01s\n",
      "[2025-03-16 23:13:32] [INFO] API response received in 3.94s\n",
      "[2025-03-16 23:13:32] [INFO] Processing image (53/734): frame_0139.png\n",
      "[2025-03-16 23:13:32] [INFO] Image encoded in 0.05s\n",
      "[2025-03-16 23:13:36] [INFO] API response received in 3.88s\n",
      "[2025-03-16 23:13:36] [INFO] Processing image (54/734): frame_0134.png\n",
      "[2025-03-16 23:13:36] [INFO] Image encoded in 0.07s\n",
      "[2025-03-16 23:13:39] [INFO] API response received in 3.62s\n",
      "[2025-03-16 23:13:39] [INFO] Processing image (55/734): frame_0352.png\n",
      "[2025-03-16 23:13:39] [INFO] Image encoded in 0.03s\n",
      "[2025-03-16 23:13:43] [INFO] API response received in 3.81s\n",
      "[2025-03-16 23:13:43] [INFO] Processing image (56/734): frame_0292.png\n",
      "[2025-03-16 23:13:43] [INFO] Image encoded in 0.05s\n",
      "[2025-03-16 23:13:47] [INFO] API response received in 4.05s\n",
      "[2025-03-16 23:13:47] [INFO] Processing image (57/734): frame_0102.png\n",
      "[2025-03-16 23:13:47] [INFO] Image encoded in 0.09s\n",
      "[2025-03-16 23:13:52] [INFO] API response received in 4.99s\n",
      "[2025-03-16 23:13:52] [INFO] Processing image (58/734): frame_0198.png\n",
      "[2025-03-16 23:13:53] [INFO] Image encoded in 0.10s\n",
      "[2025-03-16 23:13:56] [INFO] API response received in 3.88s\n",
      "[2025-03-16 23:13:56] [INFO] Processing image (59/734): frame_0456.png\n",
      "[2025-03-16 23:13:56] [INFO] Image encoded in 0.06s\n",
      "[2025-03-16 23:14:01] [INFO] API response received in 4.78s\n",
      "[2025-03-16 23:14:01] [INFO] Processing image (60/734): frame_0056.png\n",
      "[2025-03-16 23:14:01] [INFO] Image encoded in 0.00s\n",
      "[2025-03-16 23:14:06] [INFO] API response received in 4.93s\n",
      "[2025-03-16 23:14:06] [INFO] Processing image (61/734): frame_0430.png\n",
      "[2025-03-16 23:14:06] [INFO] Image encoded in 0.06s\n",
      "[2025-03-16 23:14:12] [INFO] API response received in 5.68s\n",
      "[2025-03-16 23:14:12] [INFO] Processing image (62/734): frame_0578.png\n",
      "[2025-03-16 23:14:12] [INFO] Image encoded in 0.08s\n",
      "[2025-03-16 23:14:16] [INFO] API response received in 4.30s\n",
      "[2025-03-16 23:14:16] [INFO] Processing image (63/734): frame_0337.png\n",
      "[2025-03-16 23:14:16] [INFO] Image encoded in 0.04s\n",
      "[2025-03-16 23:14:20] [INFO] API response received in 3.67s\n",
      "[2025-03-16 23:14:20] [INFO] Processing image (64/734): frame_0052.png\n",
      "[2025-03-16 23:14:20] [INFO] Image encoded in 0.07s\n",
      "[2025-03-16 23:14:26] [INFO] API response received in 6.08s\n",
      "[2025-03-16 23:14:26] [INFO] Processing image (65/734): frame_0180.png\n",
      "[2025-03-16 23:14:26] [INFO] Image encoded in 0.02s\n",
      "[2025-03-16 23:14:31] [INFO] API response received in 4.63s\n",
      "[2025-03-16 23:14:31] [INFO] Processing image (66/734): frame_0677.png\n",
      "[2025-03-16 23:14:31] [INFO] Image encoded in 0.09s\n",
      "[2025-03-16 23:14:35] [INFO] API response received in 3.91s\n",
      "[2025-03-16 23:14:35] [INFO] Processing image (67/734): frame_0293.png\n",
      "[2025-03-16 23:14:35] [INFO] Image encoded in 0.03s\n",
      "[2025-03-16 23:14:40] [INFO] API response received in 5.17s\n",
      "[2025-03-16 23:14:40] [INFO] Processing image (68/734): frame_0686.png\n",
      "[2025-03-16 23:14:40] [INFO] Image encoded in 0.03s\n",
      "[2025-03-16 23:14:44] [INFO] API response received in 4.35s\n",
      "[2025-03-16 23:14:44] [INFO] Processing image (69/734): frame_0696.png\n",
      "[2025-03-16 23:14:45] [INFO] Image encoded in 0.06s\n",
      "[2025-03-16 23:14:48] [INFO] API response received in 3.27s\n",
      "[2025-03-16 23:14:48] [INFO] Processing image (70/734): frame_0472.png\n",
      "[2025-03-16 23:14:48] [INFO] Image encoded in 0.12s\n",
      "[2025-03-16 23:14:52] [INFO] API response received in 4.27s\n",
      "[2025-03-16 23:14:52] [INFO] Processing image (71/734): frame_0693.png\n",
      "[2025-03-16 23:14:52] [INFO] Image encoded in 0.07s\n",
      "[2025-03-16 23:14:57] [INFO] API response received in 4.85s\n",
      "[2025-03-16 23:14:57] [INFO] Processing image (72/734): frame_0720.png\n",
      "[2025-03-16 23:14:57] [INFO] Image encoded in 0.02s\n",
      "[2025-03-16 23:15:02] [INFO] API response received in 5.21s\n",
      "[2025-03-16 23:15:02] [INFO] Processing image (73/734): frame_0409.png\n",
      "[2025-03-16 23:15:02] [INFO] Image encoded in 0.02s\n",
      "[2025-03-16 23:15:06] [INFO] API response received in 4.14s\n",
      "[2025-03-16 23:15:06] [INFO] Processing image (74/734): frame_0051.png\n",
      "[2025-03-16 23:15:07] [INFO] Image encoded in 0.03s\n",
      "[2025-03-16 23:15:11] [INFO] API response received in 4.05s\n",
      "[2025-03-16 23:15:11] [INFO] Processing image (75/734): frame_0226.png\n",
      "[2025-03-16 23:15:11] [INFO] Image encoded in 0.01s\n",
      "[2025-03-16 23:15:14] [INFO] API response received in 3.75s\n",
      "[2025-03-16 23:15:14] [INFO] Processing image (76/734): frame_0592.png\n",
      "[2025-03-16 23:15:14] [INFO] Image encoded in 0.03s\n",
      "[2025-03-16 23:15:19] [INFO] API response received in 4.86s\n",
      "[2025-03-16 23:15:19] [INFO] Processing image (77/734): frame_0373.png\n",
      "[2025-03-16 23:15:19] [INFO] Image encoded in 0.04s\n",
      "[2025-03-16 23:15:23] [INFO] API response received in 3.53s\n",
      "[2025-03-16 23:15:23] [INFO] Processing image (78/734): frame_0537.png\n",
      "[2025-03-16 23:15:23] [INFO] Image encoded in 0.13s\n",
      "[2025-03-16 23:15:29] [INFO] API response received in 5.68s\n",
      "[2025-03-16 23:15:29] [INFO] Processing image (79/734): frame_0314.png\n",
      "[2025-03-16 23:15:29] [INFO] Image encoded in 0.03s\n",
      "[2025-03-16 23:15:31] [INFO] API response received in 2.49s\n",
      "[2025-03-16 23:15:31] [INFO] Processing image (80/734): frame_0339.png\n",
      "[2025-03-16 23:15:31] [INFO] Image encoded in 0.23s\n",
      "[2025-03-16 23:15:35] [INFO] API response received in 4.00s\n",
      "[2025-03-16 23:15:35] [INFO] Processing image (81/734): frame_0272.png\n",
      "[2025-03-16 23:15:35] [INFO] Image encoded in 0.04s\n",
      "[2025-03-16 23:15:40] [INFO] API response received in 4.46s\n",
      "[2025-03-16 23:15:40] [INFO] Processing image (82/734): frame_0594.png\n",
      "[2025-03-16 23:15:40] [INFO] Image encoded in 0.04s\n"
     ]
    }
   ],
   "source": [
    "base_path = \"/scratch/jsong132/Can_LLM_Learn_New_Language\"\n",
    "version = \"v2\"\n",
    "\n",
    "drama_list = [\"Juilliard•NYC VLOG 석사 2학년 시이작!\", \"test\", \"고물가시대 혜자로운 코스트코 장보기\", \"그때 그 시절 우리가 사랑했던 원두\", \"나 가을 타나봐\", \"나폴리 맛피아 PICK 최애 스패니시 다이닝 맛집\"]\n",
    "\n",
    "for drama_folder_name in drama_list:\n",
    "    process(base_path, drama_folder_name, version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Juilliard•NYC VLOG 석사 2학년 시이작!\n",
      "이미지 파일 개수: 734\n",
      "예상 시간:  1.4272222222222224 시간\n",
      "test\n",
      "이미지 파일 개수: 21\n",
      "예상 시간:  0.04083333333333334 시간\n",
      "고물가시대 혜자로운 코스트코 장보기\n",
      "이미지 파일 개수: 629\n",
      "예상 시간:  1.2230555555555556 시간\n",
      "그때 그 시절 우리가 사랑했던 원두\n",
      "이미지 파일 개수: 413\n",
      "예상 시간:  0.8030555555555555 시간\n",
      "나 가을 타나봐\n",
      "이미지 파일 개수: 524\n",
      "예상 시간:  1.018888888888889 시간\n",
      "나폴리 맛피아 PICK 최애 스패니시 다이닝 맛집\n",
      "이미지 파일 개수: 942\n",
      "예상 시간:  1.8316666666666668 시간\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def check_img(drama_folder_name):\n",
    "    # 경로 설정\n",
    "    base_path = \"/scratch/jsong132/Can_LLM_Learn_New_Language\"\n",
    "    version = \"v2\"\n",
    "    image_dir = Path(f'{base_path}/Data_Images/{drama_folder_name}')\n",
    "    \n",
    "    # 이미지 확장자 설정\n",
    "    VALID_EXTENSIONS = ('.png', '.jpg', '.jpeg')\n",
    "    \n",
    "    # 이미지 파일 개수 확인\n",
    "    image_files = [f for f in image_dir.iterdir() if f.is_file() and f.suffix.lower() in VALID_EXTENSIONS]\n",
    "    \n",
    "    # 이미지 파일 개수 출력\n",
    "    print(drama_folder_name)\n",
    "    print(f\"이미지 파일 개수: {len(image_files)}\")\n",
    "    print(\"예상 시간: \", len(image_files)*7/60/60, \"시간\")\n",
    "\n",
    "check_img(\"Juilliard•NYC VLOG 석사 2학년 시이작!\")\n",
    "check_img(\"test\")\n",
    "check_img(\"고물가시대 혜자로운 코스트코 장보기\")\n",
    "check_img(\"그때 그 시절 우리가 사랑했던 원두\")\n",
    "check_img(\"나 가을 타나봐\")\n",
    "check_img(\"나폴리 맛피아 PICK 최애 스패니시 다이닝 맛집\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON 파일이 수정되어 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "# Don't need to do\n",
    "# Extra, this is not a main process\n",
    "# Make .json file readible\n",
    "# json_pretty.py\n",
    "# Make json file readible.\n",
    "################################################\n",
    "\n",
    "import json\n",
    "import textwrap\n",
    "\n",
    "# JSON 파일 로드\n",
    "with open(final_output, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# response 값을 50자씩 나누어 배열로 분할\n",
    "for item in data:\n",
    "    if 'response' in item:\n",
    "        # 50자씩 나누기\n",
    "        wrapped_text = textwrap.wrap(item['response'], width=100)\n",
    "        item['response'] = wrapped_text\n",
    "\n",
    "# 수정된 JSON 파일 저장\n",
    "with open(output_pretty, 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"JSON 파일이 수정되어 저장되었습니다.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
