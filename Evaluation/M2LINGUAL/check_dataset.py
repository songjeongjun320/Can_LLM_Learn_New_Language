#!/usr/bin/env python3
from datasets import load_dataset
from collections import Counter
import pandas as pd

def main():
    try:
        # 1. ë°ì´í„°ì…‹ ë¡œë“œ
        print("ğŸ” ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘...")
        ds = load_dataset("ServiceNow-AI/M2Lingual", "full_data")
        print(f"âœ… ë¡œë“œ ì™„ë£Œ! (ì „ì²´ ìƒ˜í”Œ ìˆ˜: {len(ds['train'])})")
        
        # 2. ì‹¤ì œ ë°ì´í„° êµ¬ì¡° í™•ì¸ (ìƒ˜í”Œ 1ê°œ ì¶œë ¥)
        print("\nğŸ“Š ë°ì´í„° êµ¬ì¡° ì˜ˆì‹œ:")
        print(ds["train"][0])

        # 3. í•œêµ­ì–´ ë°ì´í„° í•„í„°ë§ (ìˆ˜ì •ëœ ë²„ì „)
        print("\nğŸ”„ í•œêµ­ì–´ ë°ì´í„° í•„í„°ë§...")
        ko_data = ds["train"].filter(lambda x: x["language"] == "ko")
        print(f"ğŸ‡°ğŸ‡· í•œêµ­ì–´ ìƒ˜í”Œ ìˆ˜: {len(ko_data)}")

        if len(ko_data) > 0:
            # 4. í•œêµ­ì–´ ìƒ˜í”Œ ë¶„ì„
            print("\nğŸ“ í•œêµ­ì–´ ìƒ˜í”Œ ë¶„ì„:")
            
            # 4-1. íƒœìŠ¤í¬ ìœ í˜• ë¶„í¬
            task_counts = Counter(ko_data["task"])
            print("\nğŸ”§ íƒœìŠ¤í¬ ìœ í˜• ë¶„í¬:")
            for task, count in task_counts.most_common():
                print(f"- {task}: {count}ê°œ")
            
            # 4-2. ëŒ€í™” í„´ ìˆ˜ ë¶„ì„
            avg_turns = sum(ko_data["no_of_turns"]) / len(ko_data)
            print(f"\nğŸ”„ í‰ê·  ëŒ€í™” í„´ ìˆ˜: {avg_turns:.1f}")
            
            # 4-3. ìƒ˜í”Œ ì¶œë ¥
            print("\nğŸ’¬ ìƒ˜í”Œ ëŒ€í™”:")
            sample = ko_data[0]
            for turn in sample["conversation"]:
                print(f"[{turn['role']}] {turn['content']}")

            # 5. ë°ì´í„° ì €ì¥
            print("\nğŸ’¾ ë°ì´í„° ì €ì¥ ì¤‘...")
            pd.DataFrame(ko_data).to_json("m2lingual_korean.json", orient="records", force_ascii=False)
            print("âœ… ì €ì¥ ì™„ë£Œ: m2lingual_korean.json")
        else:
            print("âš ï¸ í•œêµ­ì–´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    main()