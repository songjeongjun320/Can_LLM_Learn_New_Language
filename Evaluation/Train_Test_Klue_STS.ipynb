{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefd2b82-2b63-4bb3-b58e-276a05caa845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Dataset already exists: ./klue_sts.json\n",
      "INFO:__main__:JSON loading...\n",
      "INFO:__main__:train data: 11668, valid data: 519\n",
      "INFO:__main__:Load model: olmo7B-v12-80000\n",
      "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2edb7c29c6a54a0093bf5dd7c0dc95d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsong132/.local/lib/python3.11/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "INFO:__main__:Reset Trainer...\n",
      "WARNING:accelerate.utils.other:Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='103' max='2187' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 103/2187 05:17 < 1:49:04, 0.32 it/s, Epoch 0.14/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import logging\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 로깅 설정\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# 경로 및 하이퍼파라미터 설정\n",
    "MODEL_PATH = \"olmo7B-v12-80000\"\n",
    "OUTPUT_DIR = \"olmo7B-klue-sts\"\n",
    "DATA_CACHE_DIR = \"./klue_sts_cache\"\n",
    "JSON_DATASET_PATH = \"./klue_sts.json\"\n",
    "MAX_LENGTH = 512\n",
    "MAX_EVAL_SAMPLES = 200\n",
    "\n",
    "# 데이터셋 준비 함수 - JSON 파일 생성\n",
    "def prepare_dataset_json():\n",
    "    \"\"\"KLUE STS 데이터셋을 불러와서 JSON 파일로 변환합니다.\"\"\"\n",
    "    if os.path.exists(JSON_DATASET_PATH):\n",
    "        logger.info(f\"Dataset already exists: {JSON_DATASET_PATH}\")\n",
    "        return\n",
    "    \n",
    "    logger.info(\"KLUE STS dataset loading...\")\n",
    "    klue_sts = load_dataset(\"klue\", \"sts\", cache_dir=DATA_CACHE_DIR)\n",
    "    \n",
    "    # 학습 및 검증 데이터를 위한 리스트\n",
    "    train_samples = []\n",
    "    val_samples = []\n",
    "    \n",
    "    # 함수: 프롬프트와 완성 텍스트 생성\n",
    "    def create_prompt(sentence1, sentence2):\n",
    "        return f\"Analyze the following sentence pairs and provide a similarity score between 0 and 5, where 0 means completely different and 5 means identical in meaning. Sentence 1: {sentence1} Sentence 2: {sentence2}\"\n",
    "\n",
    "    def create_completion(score):\n",
    "        # 정수로 반올림된 점수 반환\n",
    "        return f\" The similarity score is {score}\"\n",
    "    \n",
    "    # 학습 데이터 준비\n",
    "    logger.info(\"Creating Klue_dataset.json ...\")\n",
    "    for item in tqdm(klue_sts[\"train\"]):\n",
    "        sentence1 = item[\"sentence1\"]\n",
    "        sentence2 = item[\"sentence2\"]\n",
    "        score = item[\"labels\"][\"label\"]  # 0-5 척도\n",
    "        \n",
    "        # 스코어 정규화\n",
    "        normalized_score = max(0, min(5, score))\n",
    "        \n",
    "        sample = {\n",
    "            \"input\": create_prompt(sentence1, sentence2),\n",
    "            \"output\": create_completion(normalized_score)\n",
    "        }\n",
    "        train_samples.append(sample)\n",
    "    \n",
    "    # 검증 데이터 준비 (메모리 절약을 위해 일부만 사용)\n",
    "    logger.info(\"Translating Valid data...\")\n",
    "    val_subset = klue_sts[\"validation\"]\n",
    "    for item in tqdm(val_subset):\n",
    "        sentence1 = item[\"sentence1\"]\n",
    "        sentence2 = item[\"sentence2\"]\n",
    "        score = item[\"labels\"][\"label\"]\n",
    "        \n",
    "        normalized_score = max(0, min(5, score))\n",
    "        \n",
    "        sample = {\n",
    "            \"input\": create_prompt(sentence1, sentence2),\n",
    "            \"output\": create_completion(normalized_score)\n",
    "        }\n",
    "        val_samples.append(sample)\n",
    "    \n",
    "    # JSON 파일로 저장\n",
    "    dataset = {\n",
    "        \"train\": train_samples,\n",
    "        \"validation\": val_samples\n",
    "    }\n",
    "    \n",
    "    logger.info(f\"JSON dataset saving... (train: {len(train_samples)}, valid: {len(val_samples)})\")\n",
    "    with open(JSON_DATASET_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(dataset, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    logger.info(f\"Created klue_sts dataset: {JSON_DATASET_PATH}\")\n",
    "\n",
    "# 데이터 전처리 함수\n",
    "def preprocess_function(examples, tokenizer, max_length=MAX_LENGTH):\n",
    "    # 프롬프트 형식\n",
    "    inputs = tokenizer([ex for ex in examples[\"input\"]], \n",
    "                      truncation=True, \n",
    "                      max_length=max_length,\n",
    "                      padding=\"max_length\",\n",
    "                      return_tensors=\"pt\")\n",
    "    \n",
    "    # 출력 토큰화\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer([ex for ex in examples[\"output\"]], \n",
    "                         truncation=True, \n",
    "                         max_length=128,  # 출력은 짧기 때문에 더 작은 길이 사용\n",
    "                         padding=\"max_length\",\n",
    "                         return_tensors=\"pt\")\n",
    "    \n",
    "    # 라벨 처리: -100은 손실 계산에서 무시됨\n",
    "    for i in range(len(labels[\"input_ids\"])):\n",
    "        labels[\"input_ids\"][i][labels[\"input_ids\"][i] == tokenizer.pad_token_id] = -100\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": inputs[\"input_ids\"],\n",
    "        \"attention_mask\": inputs[\"attention_mask\"],\n",
    "        \"labels\": labels[\"input_ids\"]\n",
    "    }\n",
    "\n",
    "# 메인 학습 함수\n",
    "def train_model():\n",
    "    # 데이터셋 준비\n",
    "    prepare_dataset_json()\n",
    "    \n",
    "    # 데이터셋 로드\n",
    "    logger.info(\"JSON loading...\")\n",
    "    with open(JSON_DATASET_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    train_data = data[\"train\"]\n",
    "    val_data = data[\"validation\"]\n",
    "    \n",
    "    logger.info(f\"train data: {len(train_data)}, valid data: {len(val_data)}\")\n",
    "    \n",
    "    # 모델 및 토크나이저 로드\n",
    "    logger.info(f\"Load model: {MODEL_PATH}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "    \n",
    "    # 특수 토큰 확인 및 설정\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # bfloat16 정밀도로 모델 로드 (메모리 효율성 증가)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_PATH,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\"  # 자동으로 GPU에 모델 분산\n",
    "    )\n",
    "    \n",
    "    # 학습용 데이터셋 생성\n",
    "    from torch.utils.data import Dataset\n",
    "    \n",
    "    class SimpleDataset(Dataset):\n",
    "        def __init__(self, data, tokenizer, max_length):\n",
    "            self.data = data\n",
    "            self.tokenizer = tokenizer\n",
    "            self.max_length = max_length\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            item = self.data[idx]\n",
    "            prompt = item[\"input\"]\n",
    "            completion = item[\"output\"]\n",
    "            \n",
    "            # 프롬프트와 완성 결합\n",
    "            full_text = prompt + completion\n",
    "            \n",
    "            # 토큰화\n",
    "            encoded = self.tokenizer(\n",
    "                full_text,\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                padding=\"max_length\",\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            \n",
    "            # 프롬프트 부분 토큰화 (라벨 마스킹용)\n",
    "            prompt_encoded = self.tokenizer(\n",
    "                prompt,\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            \n",
    "            # 라벨 생성: 프롬프트 부분은 -100으로 마스킹\n",
    "            labels = encoded[\"input_ids\"].clone().squeeze(0)\n",
    "            prompt_length = prompt_encoded[\"input_ids\"].shape[1]\n",
    "            labels[:prompt_length] = -100\n",
    "            \n",
    "            return {\n",
    "                \"input_ids\": encoded[\"input_ids\"].squeeze(0),\n",
    "                \"attention_mask\": encoded[\"attention_mask\"].squeeze(0),\n",
    "                \"labels\": labels\n",
    "            }\n",
    "    \n",
    "    # 데이터셋 생성\n",
    "    train_dataset = SimpleDataset(train_data, tokenizer, MAX_LENGTH)\n",
    "    val_dataset = SimpleDataset(val_data, tokenizer, MAX_LENGTH)\n",
    "    \n",
    "    # 데이터 콜레이터\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer,\n",
    "        mlm=False\n",
    "    )\n",
    "    \n",
    "    # 학습 하이퍼파라미터 설정\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=200,\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        gradient_accumulation_steps=4,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        save_total_limit=3,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=400,\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_steps=100,\n",
    "        fp16=False,\n",
    "        bf16=True,  # bfloat16 정밀도 사용\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        warmup_ratio=0.1,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        report_to=\"none\",\n",
    "        gradient_checkpointing=True,  # 메모리 절약을 위한 그래디언트 체크포인팅\n",
    "        optim=\"adamw_torch\",  # PyTorch 구현 사용\n",
    "    )\n",
    "    \n",
    "    # 얼리 스토핑 콜백\n",
    "    early_stopping_callback = EarlyStoppingCallback(\n",
    "        early_stopping_patience=3\n",
    "    )\n",
    "    \n",
    "    # 트레이너 초기화 및 학습\n",
    "    logger.info(\"Reset Trainer...\")\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        data_collator=data_collator,\n",
    "        callbacks=[early_stopping_callback],\n",
    "    )\n",
    "    \n",
    "    # 학습 실행\n",
    "    trainer.train()\n",
    "    \n",
    "    # 최종 모델 및 토크나이저 저장\n",
    "    final_model_path = os.path.join(OUTPUT_DIR, \"final\")\n",
    "    logger.info(f\"Final Model: {final_model_path}\")\n",
    "    model.save_pretrained(final_model_path)\n",
    "    tokenizer.save_pretrained(final_model_path)\n",
    "    \n",
    "    logger.info(\"Tuned!\")\n",
    "    return model, tokenizer\n",
    "\n",
    "# 모델 평가 함수\n",
    "def evaluate_model(model, tokenizer):\n",
    "    logger.info(\"Evaluating the model...\")\n",
    "    \n",
    "    # KLUE STS 데이터셋 로드\n",
    "    klue_sts = load_dataset(\"klue\", \"sts\", cache_dir=DATA_CACHE_DIR)\n",
    "    \n",
    "    # 평가용 하위 집합\n",
    "    val_subset = klue_sts[\"validation\"]\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    true_scores = []\n",
    "    pred_scores = []\n",
    "    \n",
    "\n",
    "    for item in tqdm(val_subset):\n",
    "        sentence1 = item[\"sentence1\"]\n",
    "        sentence2 = item[\"sentence2\"]\n",
    "        true_score = item[\"labels\"][\"label\"]\n",
    "        \n",
    "        # 프롬프트 생성\n",
    "        prompt = f\"Analyze the following sentence pairs and provide a similarity score between 0 and 5, where 0 means completely different and 5 means identical in meaning. Sentence 1: {sentence1} Sentence 2: {sentence2}\"\n",
    "        \n",
    "        # 토큰화\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        \n",
    "        # 추론\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                inputs[\"input_ids\"],\n",
    "                max_new_tokens=20,\n",
    "                temperature=0.1,\n",
    "                num_return_sequences=1,\n",
    "                pad_token_id=tokenizer.pad_token_id\n",
    "            )\n",
    "        \n",
    "        # 결과 디코딩\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        # 점수 추출 (실수 처리)\n",
    "        match = re.search(r'similarity score is (\\d+(\\.\\d+)?)', generated_text)\n",
    "        if match:\n",
    "            predicted_score = float(match.group(1))  # 실수로 변환\n",
    "            if 0 <= predicted_score <= 5:\n",
    "                true_scores.append(true_score)\n",
    "                pred_scores.append(predicted_score)\n",
    "            else:\n",
    "                logger.warning(f\"Out of scope (0-5): {predicted_score}\")\n",
    "        else:\n",
    "            logger.warning(f\"Can't extract the label: {generated_text}\")\n",
    "    \n",
    "    # 메트릭 계산\n",
    "    if true_scores and pred_scores:\n",
    "        pearson_corr = np.corrcoef(true_scores, pred_scores)[0, 1]\n",
    "        rmse = np.sqrt(mean_squared_error(true_scores, pred_scores))\n",
    "        \n",
    "        logger.info(f\"Eval result:\")\n",
    "        logger.info(f\"Evaluated samples: {len(true_scores)}\")\n",
    "        logger.info(f\"Pearson Correction: {pearson_corr:.4f}\")\n",
    "        logger.info(f\"RMSE: {rmse:.4f}\")\n",
    "        \n",
    "        # 평가 결과 저장\n",
    "        with open(os.path.join(OUTPUT_DIR, \"eval_results.json\"), \"w\") as f:\n",
    "            json.dump({\n",
    "                \"pearson_correlation\": float(pearson_corr),\n",
    "                \"rmse\": float(rmse),\n",
    "                \"num_samples\": len(true_scores)\n",
    "            }, f, indent=2)\n",
    "    else:\n",
    "        logger.warning(\"No valid prediction.\")\n",
    "\n",
    "# 메인 실행 함수\n",
    "if __name__ == \"__main__\":\n",
    "    # 출력 디렉토리 생성\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    os.makedirs(DATA_CACHE_DIR, exist_ok=True)\n",
    "    \n",
    "    # 모델 학습\n",
    "    model, tokenizer = train_model()\n",
    "    \n",
    "    # 모델 평가\n",
    "    evaluate_model(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092b8fcd-ff19-460d-b4d0-6b613c30d4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f8ce2c-0933-4d90-8841-d383812ba5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deff6702-040b-483a-bebb-102943d63f1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['guid', 'source', 'sentence1', 'sentence2', 'labels'],\n",
      "    num_rows: 11668\n",
      "})\n",
      "Dataset({\n",
      "    features: ['guid', 'source', 'sentence1', 'sentence2', 'labels'],\n",
      "    num_rows: 519\n",
      "})\n",
      "0th data\n",
      "sentence1:  숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다.\n",
      "sentence2:  숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다.\n",
      "similarity:  3.7\n",
      "1th data\n",
      "sentence1:  위반행위 조사 등을 거부·방해·기피한 자는 500만원 이하 과태료 부과 대상이다.\n",
      "sentence2:  시민들 스스로 자발적인 예방 노력을 한 것은 아산 뿐만이 아니었다.\n",
      "similarity:  0.0\n",
      "2th data\n",
      "sentence1:  회사가 보낸 메일은 이 지메일이 아니라 다른 지메일 계정으로 전달해줘.\n",
      "sentence2:  사람들이 주로 네이버 메일을 쓰는 이유를 알려줘\n",
      "similarity:  0.3\n",
      "3th data\n",
      "sentence1:  긴급 고용안정지원금은 지역고용대응 등 특별지원금, 지자체별 소상공인 지원사업, 취업성공패키지, 청년구직활동지원금, 긴급복지지원제도 지원금과는 중복 수급이 불가능하다.\n",
      "sentence2:  고용보험이 1차 고용안전망이라면, 국민취업지원제도는 2차 고용안전망입니다.\n",
      "similarity:  0.6\n",
      "4th data\n",
      "sentence1:  호스트의 답장이 늦으나, 개선될 것으로 보입니다.\n",
      "sentence2:  호스트 응답이 늦었지만 개선될 것으로 보입니다.\n",
      "similarity:  4.7\n",
      "5th data\n",
      "sentence1:  정부가 새로운 일자리를 직접 창출하는 노력도 배가하겠습니다.\n",
      "sentence2:  세계에서 우리만큼 오랜 역사와 문화를 공유하는 가까운 이웃이 없습니다.\n",
      "similarity:  0.0\n",
      "6th data\n",
      "sentence1:  지하철을 타도 30분안에는 이동이 가능합니다!\n",
      "sentence2:  지하철을 탄다고 해도, 30분이면 그곳에 도착할 수 있어요!\n",
      "similarity:  4.0\n",
      "7th data\n",
      "sentence1:  사례집은 국립환경과학원 누리집(ecolibrary.me.go.kr)에서 12일부터 볼 수 있다.\n",
      "sentence2:  주말을 제외한 평일 오후 12시 30분부터 문예회관 공식 페이스북과 유튜브에서는 지역 예술인들이 중심이 된 서양음악, 국악, 댄스 등의 공연을 실시간으로 감상할 수 있다.\n",
      "similarity:  0.0\n",
      "8th data\n",
      "sentence1:  환퐁기 작동 방법 좀 설명해줘\n",
      "sentence2:  조명등 낮에 켜놓으면 큰일나\n",
      "similarity:  0.1\n",
      "9th data\n",
      "sentence1:  새로운 친구들을 만나고 싶을때 아주 추천합니다.\n",
      "sentence2:  새로운 친구들을 만나고 싶을 때 추천합니다.\n",
      "similarity:  4.4\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "# KLUE STS dataset\n",
    "#######################################################\n",
    "from datasets import load_dataset\n",
    "\n",
    "klue_sts = load_dataset('klue', 'sts')\n",
    "   \n",
    "# 데이터셋 확인 (예: train 데이터셋의 50번째 샘플 확인)\n",
    "print(klue_sts['train'])  # 또는 'validation' 또는 'test'에 접근 가능\n",
    "\n",
    "# 예시로 'validation' 데이터셋을 확인\n",
    "print(klue_sts['validation'])\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"{i}th data\")\n",
    "    print(\"sentence1: \", klue_sts['train'][i][\"sentence1\"])\n",
    "    print(\"sentence2: \", klue_sts['train'][i][\"sentence2\"])\n",
    "    print(\"similarity: \", klue_sts['train'][i][\"labels\"][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a9e130-fb81-45e1-9f6f-490ad34ecaf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
