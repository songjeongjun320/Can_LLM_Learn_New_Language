{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefd2b82-2b63-4bb3-b58e-276a05caa845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Dataset already exists: ./klue_sts.json\n",
      "INFO:__main__:JSON loading...\n",
      "INFO:__main__:train data: 11668, valid data: 519\n",
      "INFO:__main__:Load model: olmo7B-v12-80000\n",
      "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2edb7c29c6a54a0093bf5dd7c0dc95d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsong132/.local/lib/python3.11/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "INFO:__main__:Reset Trainer...\n",
      "WARNING:accelerate.utils.other:Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='103' max='2187' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 103/2187 05:17 < 1:49:04, 0.32 it/s, Epoch 0.14/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import logging\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ë¡œê¹… ì„¤ì •\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ê²½ë¡œ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "MODEL_PATH = \"olmo7B-v12-80000\"\n",
    "OUTPUT_DIR = \"olmo7B-klue-sts\"\n",
    "DATA_CACHE_DIR = \"./klue_sts_cache\"\n",
    "JSON_DATASET_PATH = \"./klue_sts.json\"\n",
    "MAX_LENGTH = 512\n",
    "MAX_EVAL_SAMPLES = 200\n",
    "\n",
    "# ë°ì´í„°ì…‹ ì¤€ë¹„ í•¨ìˆ˜ - JSON íŒŒì¼ ìƒì„±\n",
    "def prepare_dataset_json():\n",
    "    \"\"\"KLUE STS ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì™€ì„œ JSON íŒŒì¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "    if os.path.exists(JSON_DATASET_PATH):\n",
    "        logger.info(f\"Dataset already exists: {JSON_DATASET_PATH}\")\n",
    "        return\n",
    "    \n",
    "    logger.info(\"KLUE STS dataset loading...\")\n",
    "    klue_sts = load_dataset(\"klue\", \"sts\", cache_dir=DATA_CACHE_DIR)\n",
    "    \n",
    "    # í•™ìŠµ ë° ê²€ì¦ ë°ì´í„°ë¥¼ ìœ„í•œ ë¦¬ìŠ¤íŠ¸\n",
    "    train_samples = []\n",
    "    val_samples = []\n",
    "    \n",
    "    # í•¨ìˆ˜: í”„ë¡¬í”„íŠ¸ì™€ ì™„ì„± í…ìŠ¤íŠ¸ ìƒì„±\n",
    "    def create_prompt(sentence1, sentence2):\n",
    "        return f\"Analyze the following sentence pairs and provide a similarity score between 0 and 5, where 0 means completely different and 5 means identical in meaning. Sentence 1: {sentence1} Sentence 2: {sentence2}\"\n",
    "\n",
    "    def create_completion(score):\n",
    "        # ì •ìˆ˜ë¡œ ë°˜ì˜¬ë¦¼ëœ ì ìˆ˜ ë°˜í™˜\n",
    "        return f\" The similarity score is {score}\"\n",
    "    \n",
    "    # í•™ìŠµ ë°ì´í„° ì¤€ë¹„\n",
    "    logger.info(\"Creating Klue_dataset.json ...\")\n",
    "    for item in tqdm(klue_sts[\"train\"]):\n",
    "        sentence1 = item[\"sentence1\"]\n",
    "        sentence2 = item[\"sentence2\"]\n",
    "        score = item[\"labels\"][\"label\"]  # 0-5 ì²™ë„\n",
    "        \n",
    "        # ìŠ¤ì½”ì–´ ì •ê·œí™”\n",
    "        normalized_score = max(0, min(5, score))\n",
    "        \n",
    "        sample = {\n",
    "            \"input\": create_prompt(sentence1, sentence2),\n",
    "            \"output\": create_completion(normalized_score)\n",
    "        }\n",
    "        train_samples.append(sample)\n",
    "    \n",
    "    # ê²€ì¦ ë°ì´í„° ì¤€ë¹„ (ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ì¼ë¶€ë§Œ ì‚¬ìš©)\n",
    "    logger.info(\"Translating Valid data...\")\n",
    "    val_subset = klue_sts[\"validation\"]\n",
    "    for item in tqdm(val_subset):\n",
    "        sentence1 = item[\"sentence1\"]\n",
    "        sentence2 = item[\"sentence2\"]\n",
    "        score = item[\"labels\"][\"label\"]\n",
    "        \n",
    "        normalized_score = max(0, min(5, score))\n",
    "        \n",
    "        sample = {\n",
    "            \"input\": create_prompt(sentence1, sentence2),\n",
    "            \"output\": create_completion(normalized_score)\n",
    "        }\n",
    "        val_samples.append(sample)\n",
    "    \n",
    "    # JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "    dataset = {\n",
    "        \"train\": train_samples,\n",
    "        \"validation\": val_samples\n",
    "    }\n",
    "    \n",
    "    logger.info(f\"JSON dataset saving... (train: {len(train_samples)}, valid: {len(val_samples)})\")\n",
    "    with open(JSON_DATASET_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(dataset, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    logger.info(f\"Created klue_sts dataset: {JSON_DATASET_PATH}\")\n",
    "\n",
    "# ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def preprocess_function(examples, tokenizer, max_length=MAX_LENGTH):\n",
    "    # í”„ë¡¬í”„íŠ¸ í˜•ì‹\n",
    "    inputs = tokenizer([ex for ex in examples[\"input\"]], \n",
    "                      truncation=True, \n",
    "                      max_length=max_length,\n",
    "                      padding=\"max_length\",\n",
    "                      return_tensors=\"pt\")\n",
    "    \n",
    "    # ì¶œë ¥ í† í°í™”\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer([ex for ex in examples[\"output\"]], \n",
    "                         truncation=True, \n",
    "                         max_length=128,  # ì¶œë ¥ì€ ì§§ê¸° ë•Œë¬¸ì— ë” ì‘ì€ ê¸¸ì´ ì‚¬ìš©\n",
    "                         padding=\"max_length\",\n",
    "                         return_tensors=\"pt\")\n",
    "    \n",
    "    # ë¼ë²¨ ì²˜ë¦¬: -100ì€ ì†ì‹¤ ê³„ì‚°ì—ì„œ ë¬´ì‹œë¨\n",
    "    for i in range(len(labels[\"input_ids\"])):\n",
    "        labels[\"input_ids\"][i][labels[\"input_ids\"][i] == tokenizer.pad_token_id] = -100\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": inputs[\"input_ids\"],\n",
    "        \"attention_mask\": inputs[\"attention_mask\"],\n",
    "        \"labels\": labels[\"input_ids\"]\n",
    "    }\n",
    "\n",
    "# ë©”ì¸ í•™ìŠµ í•¨ìˆ˜\n",
    "def train_model():\n",
    "    # ë°ì´í„°ì…‹ ì¤€ë¹„\n",
    "    prepare_dataset_json()\n",
    "    \n",
    "    # ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "    logger.info(\"JSON loading...\")\n",
    "    with open(JSON_DATASET_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    train_data = data[\"train\"]\n",
    "    val_data = data[\"validation\"]\n",
    "    \n",
    "    logger.info(f\"train data: {len(train_data)}, valid data: {len(val_data)}\")\n",
    "    \n",
    "    # ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "    logger.info(f\"Load model: {MODEL_PATH}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "    \n",
    "    # íŠ¹ìˆ˜ í† í° í™•ì¸ ë° ì„¤ì •\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # bfloat16 ì •ë°€ë„ë¡œ ëª¨ë¸ ë¡œë“œ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ì¦ê°€)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_PATH,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\"  # ìë™ìœ¼ë¡œ GPUì— ëª¨ë¸ ë¶„ì‚°\n",
    "    )\n",
    "    \n",
    "    # í•™ìŠµìš© ë°ì´í„°ì…‹ ìƒì„±\n",
    "    from torch.utils.data import Dataset\n",
    "    \n",
    "    class SimpleDataset(Dataset):\n",
    "        def __init__(self, data, tokenizer, max_length):\n",
    "            self.data = data\n",
    "            self.tokenizer = tokenizer\n",
    "            self.max_length = max_length\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            item = self.data[idx]\n",
    "            prompt = item[\"input\"]\n",
    "            completion = item[\"output\"]\n",
    "            \n",
    "            # í”„ë¡¬í”„íŠ¸ì™€ ì™„ì„± ê²°í•©\n",
    "            full_text = prompt + completion\n",
    "            \n",
    "            # í† í°í™”\n",
    "            encoded = self.tokenizer(\n",
    "                full_text,\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                padding=\"max_length\",\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            \n",
    "            # í”„ë¡¬í”„íŠ¸ ë¶€ë¶„ í† í°í™” (ë¼ë²¨ ë§ˆìŠ¤í‚¹ìš©)\n",
    "            prompt_encoded = self.tokenizer(\n",
    "                prompt,\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            \n",
    "            # ë¼ë²¨ ìƒì„±: í”„ë¡¬í”„íŠ¸ ë¶€ë¶„ì€ -100ìœ¼ë¡œ ë§ˆìŠ¤í‚¹\n",
    "            labels = encoded[\"input_ids\"].clone().squeeze(0)\n",
    "            prompt_length = prompt_encoded[\"input_ids\"].shape[1]\n",
    "            labels[:prompt_length] = -100\n",
    "            \n",
    "            return {\n",
    "                \"input_ids\": encoded[\"input_ids\"].squeeze(0),\n",
    "                \"attention_mask\": encoded[\"attention_mask\"].squeeze(0),\n",
    "                \"labels\": labels\n",
    "            }\n",
    "    \n",
    "    # ë°ì´í„°ì…‹ ìƒì„±\n",
    "    train_dataset = SimpleDataset(train_data, tokenizer, MAX_LENGTH)\n",
    "    val_dataset = SimpleDataset(val_data, tokenizer, MAX_LENGTH)\n",
    "    \n",
    "    # ë°ì´í„° ì½œë ˆì´í„°\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer,\n",
    "        mlm=False\n",
    "    )\n",
    "    \n",
    "    # í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=200,\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        gradient_accumulation_steps=4,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        save_total_limit=3,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=400,\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_steps=100,\n",
    "        fp16=False,\n",
    "        bf16=True,  # bfloat16 ì •ë°€ë„ ì‚¬ìš©\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        warmup_ratio=0.1,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        report_to=\"none\",\n",
    "        gradient_checkpointing=True,  # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•œ ê·¸ë˜ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŒ…\n",
    "        optim=\"adamw_torch\",  # PyTorch êµ¬í˜„ ì‚¬ìš©\n",
    "    )\n",
    "    \n",
    "    # ì–¼ë¦¬ ìŠ¤í† í•‘ ì½œë°±\n",
    "    early_stopping_callback = EarlyStoppingCallback(\n",
    "        early_stopping_patience=3\n",
    "    )\n",
    "    \n",
    "    # íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™” ë° í•™ìŠµ\n",
    "    logger.info(\"Reset Trainer...\")\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        data_collator=data_collator,\n",
    "        callbacks=[early_stopping_callback],\n",
    "    )\n",
    "    \n",
    "    # í•™ìŠµ ì‹¤í–‰\n",
    "    trainer.train()\n",
    "    \n",
    "    # ìµœì¢… ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ì €ì¥\n",
    "    final_model_path = os.path.join(OUTPUT_DIR, \"final\")\n",
    "    logger.info(f\"Final Model: {final_model_path}\")\n",
    "    model.save_pretrained(final_model_path)\n",
    "    tokenizer.save_pretrained(final_model_path)\n",
    "    \n",
    "    logger.info(\"Tuned!\")\n",
    "    return model, tokenizer\n",
    "\n",
    "# ëª¨ë¸ í‰ê°€ í•¨ìˆ˜\n",
    "def evaluate_model(model, tokenizer):\n",
    "    logger.info(\"Evaluating the model...\")\n",
    "    \n",
    "    # KLUE STS ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "    klue_sts = load_dataset(\"klue\", \"sts\", cache_dir=DATA_CACHE_DIR)\n",
    "    \n",
    "    # í‰ê°€ìš© í•˜ìœ„ ì§‘í•©\n",
    "    val_subset = klue_sts[\"validation\"]\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    true_scores = []\n",
    "    pred_scores = []\n",
    "    \n",
    "\n",
    "    for item in tqdm(val_subset):\n",
    "        sentence1 = item[\"sentence1\"]\n",
    "        sentence2 = item[\"sentence2\"]\n",
    "        true_score = item[\"labels\"][\"label\"]\n",
    "        \n",
    "        # í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "        prompt = f\"Analyze the following sentence pairs and provide a similarity score between 0 and 5, where 0 means completely different and 5 means identical in meaning. Sentence 1: {sentence1} Sentence 2: {sentence2}\"\n",
    "        \n",
    "        # í† í°í™”\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        \n",
    "        # ì¶”ë¡ \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                inputs[\"input_ids\"],\n",
    "                max_new_tokens=20,\n",
    "                temperature=0.1,\n",
    "                num_return_sequences=1,\n",
    "                pad_token_id=tokenizer.pad_token_id\n",
    "            )\n",
    "        \n",
    "        # ê²°ê³¼ ë””ì½”ë”©\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        # ì ìˆ˜ ì¶”ì¶œ (ì‹¤ìˆ˜ ì²˜ë¦¬)\n",
    "        match = re.search(r'similarity score is (\\d+(\\.\\d+)?)', generated_text)\n",
    "        if match:\n",
    "            predicted_score = float(match.group(1))  # ì‹¤ìˆ˜ë¡œ ë³€í™˜\n",
    "            if 0 <= predicted_score <= 5:\n",
    "                true_scores.append(true_score)\n",
    "                pred_scores.append(predicted_score)\n",
    "            else:\n",
    "                logger.warning(f\"Out of scope (0-5): {predicted_score}\")\n",
    "        else:\n",
    "            logger.warning(f\"Can't extract the label: {generated_text}\")\n",
    "    \n",
    "    # ë©”íŠ¸ë¦­ ê³„ì‚°\n",
    "    if true_scores and pred_scores:\n",
    "        pearson_corr = np.corrcoef(true_scores, pred_scores)[0, 1]\n",
    "        rmse = np.sqrt(mean_squared_error(true_scores, pred_scores))\n",
    "        \n",
    "        logger.info(f\"Eval result:\")\n",
    "        logger.info(f\"Evaluated samples: {len(true_scores)}\")\n",
    "        logger.info(f\"Pearson Correction: {pearson_corr:.4f}\")\n",
    "        logger.info(f\"RMSE: {rmse:.4f}\")\n",
    "        \n",
    "        # í‰ê°€ ê²°ê³¼ ì €ì¥\n",
    "        with open(os.path.join(OUTPUT_DIR, \"eval_results.json\"), \"w\") as f:\n",
    "            json.dump({\n",
    "                \"pearson_correlation\": float(pearson_corr),\n",
    "                \"rmse\": float(rmse),\n",
    "                \"num_samples\": len(true_scores)\n",
    "            }, f, indent=2)\n",
    "    else:\n",
    "        logger.warning(\"No valid prediction.\")\n",
    "\n",
    "# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜\n",
    "if __name__ == \"__main__\":\n",
    "    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    os.makedirs(DATA_CACHE_DIR, exist_ok=True)\n",
    "    \n",
    "    # ëª¨ë¸ í•™ìŠµ\n",
    "    model, tokenizer = train_model()\n",
    "    \n",
    "    # ëª¨ë¸ í‰ê°€\n",
    "    evaluate_model(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092b8fcd-ff19-460d-b4d0-6b613c30d4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f8ce2c-0933-4d90-8841-d383812ba5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deff6702-040b-483a-bebb-102943d63f1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['guid', 'source', 'sentence1', 'sentence2', 'labels'],\n",
      "    num_rows: 11668\n",
      "})\n",
      "Dataset({\n",
      "    features: ['guid', 'source', 'sentence1', 'sentence2', 'labels'],\n",
      "    num_rows: 519\n",
      "})\n",
      "0th data\n",
      "sentence1:  ìˆ™ì†Œ ìœ„ì¹˜ëŠ” ì°¾ê¸° ì‰½ê³  ì¼ë°˜ì ì¸ í•œêµ­ì˜ ë°˜ì§€í•˜ ìˆ™ì†Œì…ë‹ˆë‹¤.\n",
      "sentence2:  ìˆ™ë°•ì‹œì„¤ì˜ ìœ„ì¹˜ëŠ” ì‰½ê²Œ ì°¾ì„ ìˆ˜ ìˆê³  í•œêµ­ì˜ ëŒ€í‘œì ì¸ ë°˜ì§€í•˜ ìˆ™ë°•ì‹œì„¤ì…ë‹ˆë‹¤.\n",
      "similarity:  3.7\n",
      "1th data\n",
      "sentence1:  ìœ„ë°˜í–‰ìœ„ ì¡°ì‚¬ ë“±ì„ ê±°ë¶€Â·ë°©í•´Â·ê¸°í”¼í•œ ìëŠ” 500ë§Œì› ì´í•˜ ê³¼íƒœë£Œ ë¶€ê³¼ ëŒ€ìƒì´ë‹¤.\n",
      "sentence2:  ì‹œë¯¼ë“¤ ìŠ¤ìŠ¤ë¡œ ìë°œì ì¸ ì˜ˆë°© ë…¸ë ¥ì„Â í•œ ê²ƒì€ ì•„ì‚° ë¿ë§Œì´ ì•„ë‹ˆì—ˆë‹¤.\n",
      "similarity:  0.0\n",
      "2th data\n",
      "sentence1:  íšŒì‚¬ê°€ ë³´ë‚¸ ë©”ì¼ì€ ì´ ì§€ë©”ì¼ì´ ì•„ë‹ˆë¼ ë‹¤ë¥¸ ì§€ë©”ì¼ ê³„ì •ìœ¼ë¡œ ì „ë‹¬í•´ì¤˜.\n",
      "sentence2:  ì‚¬ëŒë“¤ì´ ì£¼ë¡œ ë„¤ì´ë²„ ë©”ì¼ì„ ì“°ëŠ” ì´ìœ ë¥¼ ì•Œë ¤ì¤˜\n",
      "similarity:  0.3\n",
      "3th data\n",
      "sentence1:  ê¸´ê¸‰ ê³ ìš©ì•ˆì •ì§€ì›ê¸ˆì€ ì§€ì—­ê³ ìš©ëŒ€ì‘ ë“± íŠ¹ë³„ì§€ì›ê¸ˆ, ì§€ìì²´ë³„ ì†Œìƒê³µì¸ ì§€ì›ì‚¬ì—…, ì·¨ì—…ì„±ê³µíŒ¨í‚¤ì§€, ì²­ë…„êµ¬ì§í™œë™ì§€ì›ê¸ˆ, ê¸´ê¸‰ë³µì§€ì§€ì›ì œë„ ì§€ì›ê¸ˆê³¼ëŠ” ì¤‘ë³µ ìˆ˜ê¸‰ì´ ë¶ˆê°€ëŠ¥í•˜ë‹¤.\n",
      "sentence2:  ê³ ìš©ë³´í—˜ì´ 1ì°¨ ê³ ìš©ì•ˆì „ë§ì´ë¼ë©´, êµ­ë¯¼ì·¨ì—…ì§€ì›ì œë„ëŠ” 2ì°¨ ê³ ìš©ì•ˆì „ë§ì…ë‹ˆë‹¤.\n",
      "similarity:  0.6\n",
      "4th data\n",
      "sentence1:  í˜¸ìŠ¤íŠ¸ì˜ ë‹µì¥ì´ ëŠ¦ìœ¼ë‚˜, ê°œì„ ë  ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.\n",
      "sentence2:  í˜¸ìŠ¤íŠ¸ ì‘ë‹µì´ ëŠ¦ì—ˆì§€ë§Œ ê°œì„ ë  ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.\n",
      "similarity:  4.7\n",
      "5th data\n",
      "sentence1:  ì •ë¶€ê°€ ìƒˆë¡œìš´ ì¼ìë¦¬ë¥¼ ì§ì ‘ ì°½ì¶œí•˜ëŠ” ë…¸ë ¥ë„ ë°°ê°€í•˜ê² ìŠµë‹ˆë‹¤.\n",
      "sentence2:  ì„¸ê³„ì—ì„œ ìš°ë¦¬ë§Œí¼ ì˜¤ëœ ì—­ì‚¬ì™€ ë¬¸í™”ë¥¼ ê³µìœ í•˜ëŠ” ê°€ê¹Œìš´ ì´ì›ƒì´ ì—†ìŠµë‹ˆë‹¤.\n",
      "similarity:  0.0\n",
      "6th data\n",
      "sentence1:  ì§€í•˜ì² ì„ íƒ€ë„ 30ë¶„ì•ˆì—ëŠ” ì´ë™ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤!\n",
      "sentence2:  ì§€í•˜ì² ì„ íƒ„ë‹¤ê³  í•´ë„, 30ë¶„ì´ë©´ ê·¸ê³³ì— ë„ì°©í•  ìˆ˜ ìˆì–´ìš”!\n",
      "similarity:  4.0\n",
      "7th data\n",
      "sentence1:  ì‚¬ë¡€ì§‘ì€ êµ­ë¦½í™˜ê²½ê³¼í•™ì› ëˆ„ë¦¬ì§‘(ecolibrary.me.go.kr)ì—ì„œ 12ì¼ë¶€í„° ë³¼ ìˆ˜ ìˆë‹¤.\n",
      "sentence2:  ì£¼ë§ì„ ì œì™¸í•œ í‰ì¼ ì˜¤í›„ 12ì‹œ 30ë¶„ë¶€í„° ë¬¸ì˜ˆíšŒê´€ ê³µì‹ í˜ì´ìŠ¤ë¶ê³¼ ìœ íŠœë¸Œì—ì„œëŠ” ì§€ì—­ ì˜ˆìˆ ì¸ë“¤ì´ ì¤‘ì‹¬ì´ ëœ ì„œì–‘ìŒì•…, êµ­ì•…, ëŒ„ìŠ¤ ë“±ì˜ ê³µì—°ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°ìƒí•  ìˆ˜ ìˆë‹¤.\n",
      "similarity:  0.0\n",
      "8th data\n",
      "sentence1:  í™˜íê¸° ì‘ë™ ë°©ë²• ì¢€ ì„¤ëª…í•´ì¤˜\n",
      "sentence2:  ì¡°ëª…ë“± ë‚®ì— ì¼œë†“ìœ¼ë©´ í°ì¼ë‚˜\n",
      "similarity:  0.1\n",
      "9th data\n",
      "sentence1:  ìƒˆë¡œìš´ ì¹œêµ¬ë“¤ì„ ë§Œë‚˜ê³  ì‹¶ì„ë•Œ ì•„ì£¼ ì¶”ì²œí•©ë‹ˆë‹¤.\n",
      "sentence2:  ìƒˆë¡œìš´ ì¹œêµ¬ë“¤ì„ ë§Œë‚˜ê³  ì‹¶ì„ ë•Œ ì¶”ì²œí•©ë‹ˆë‹¤.\n",
      "similarity:  4.4\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "# KLUE STS dataset\n",
    "#######################################################\n",
    "from datasets import load_dataset\n",
    "\n",
    "klue_sts = load_dataset('klue', 'sts')\n",
    "   \n",
    "# ë°ì´í„°ì…‹ í™•ì¸ (ì˜ˆ: train ë°ì´í„°ì…‹ì˜ 50ë²ˆì§¸ ìƒ˜í”Œ í™•ì¸)\n",
    "print(klue_sts['train'])  # ë˜ëŠ” 'validation' ë˜ëŠ” 'test'ì— ì ‘ê·¼ ê°€ëŠ¥\n",
    "\n",
    "# ì˜ˆì‹œë¡œ 'validation' ë°ì´í„°ì…‹ì„ í™•ì¸\n",
    "print(klue_sts['validation'])\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"{i}th data\")\n",
    "    print(\"sentence1: \", klue_sts['train'][i][\"sentence1\"])\n",
    "    print(\"sentence2: \", klue_sts['train'][i][\"sentence2\"])\n",
    "    print(\"similarity: \", klue_sts['train'][i][\"labels\"][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a9e130-fb81-45e1-9f6f-490ad34ecaf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
