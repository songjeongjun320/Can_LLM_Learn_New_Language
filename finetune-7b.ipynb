{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:데이터 로딩 시작...\n",
      "INFO:__main__:47개 파일에서 총 81948개의 샘플을 로드했습니다.\n",
      "INFO:__main__:학습 데이터셋: 73753개, 검증 데이터셋: 8195개\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "import logging\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 로깅 설정\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# 폴더 경로 설정\n",
    "folder_path = \"./Data_Final_Reversed/\"\n",
    "\n",
    "# 모든 .json 파일을 읽어들여 데이터를 병합\n",
    "all_data = {\"input\": [], \"output\": []}\n",
    "logger.info(\"데이터 로딩 시작...\")\n",
    "file_count = 0\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".json\"):\n",
    "        file_count += 1\n",
    "        with open(os.path.join(folder_path, filename), \"r\", encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                all_data[\"input\"].extend([item[\"input\"] for item in data])\n",
    "                all_data[\"output\"].extend([item[\"output\"] for item in data])\n",
    "            except json.JSONDecodeError:\n",
    "                logger.error(f\"파일 읽기 오류: {filename}\")\n",
    "\n",
    "logger.info(f\"{file_count}개 파일에서 총 {len(all_data['input'])}개의 샘플을 로드했습니다.\")\n",
    "\n",
    "# 입력과 출력 길이가 맞는지 확인\n",
    "assert len(all_data[\"input\"]) == len(all_data[\"output\"]), \"입력과 출력 데이터 개수가 일치하지 않습니다.\"\n",
    "\n",
    "# Hugging Face Dataset으로 변환\n",
    "dataset = Dataset.from_dict(all_data)\n",
    "\n",
    "# 학습 및 검증 데이터셋 분할 (90% 학습, 10% 검증)\n",
    "dataset = dataset.train_test_split(test_size=0.1, seed=42)  # 재현성을 위한 시드 설정\n",
    "logger.info(f\"학습 데이터셋: {len(dataset['train'])}개, 검증 데이터셋: {len(dataset['test'])}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:모델 로드 중: allenai/OLMo-7B-hf\n",
      "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b75d98e2354a5c8569ab6e72412c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 및 토크나이저 로드\n",
    "base_model = \"allenai/OLMo-7B-hf\"\n",
    "logger.info(f\"모델 로드 중: {base_model}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "# 특수 토큰 확인 및 설정\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 메모리 효율을 위한 모델 로드 설정\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model, \n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"  # 자동으로 사용 가능한 GPU에 모델 분산\n",
    ")\n",
    "\n",
    "# 데이터 전처리 함수 (입력/출력 형식 수정)\n",
    "def preprocess_function(examples):\n",
    "    # 프롬프트 형식: \"Input: {input} Output: {output}\"\n",
    "    prompts = [f\"Input: {input}\\nOutput: \" for input in examples[\"input\"]]\n",
    "    inputs = tokenizer(prompts, truncation=True, max_length=1024, padding=False)\n",
    "    \n",
    "    # 출력 토큰화\n",
    "    outputs = tokenizer(examples[\"output\"], truncation=True, max_length=1024, padding=False)\n",
    "    \n",
    "    # 입력 ID와 출력 ID 결합\n",
    "    result = {\n",
    "        \"input_ids\": [],\n",
    "        \"attention_mask\": []\n",
    "    }\n",
    "    \n",
    "    for i in range(len(prompts)):\n",
    "        input_ids = inputs[\"input_ids\"][i]\n",
    "        output_ids = outputs[\"input_ids\"][i]\n",
    "        \n",
    "        # EOS 토큰 추가\n",
    "        if output_ids[-1] != tokenizer.eos_token_id:\n",
    "            output_ids.append(tokenizer.eos_token_id)\n",
    "        \n",
    "        # 입력과 출력 결합\n",
    "        combined_ids = input_ids + output_ids\n",
    "        attention_mask = [1] * len(combined_ids)\n",
    "        \n",
    "        # 최대 길이 제한\n",
    "        max_length = 1024  # 더 긴 컨텍스트 허용\n",
    "        if len(combined_ids) > max_length:\n",
    "            combined_ids = combined_ids[:max_length]\n",
    "            attention_mask = attention_mask[:max_length]\n",
    "        \n",
    "        result[\"input_ids\"].append(combined_ids)\n",
    "        result[\"attention_mask\"].append(attention_mask)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:데이터셋 토큰화 중...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d3a454f0a24de2bf56858bee0df1d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/73753 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4617d562bc1429691cacc893fdc58cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/8195 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터셋 전처리\n",
    "logger.info(\"데이터셋 토큰화 중...\")\n",
    "tokenized_train = dataset[\"train\"].map(\n",
    "    preprocess_function, \n",
    "    batched=True, \n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    "    num_proc=4  # 병렬 처리\n",
    ")\n",
    "tokenized_eval = dataset[\"test\"].map(\n",
    "    preprocess_function, \n",
    "    batched=True, \n",
    "    remove_columns=dataset[\"test\"].column_names,\n",
    "    num_proc=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:트레이너 초기화 및 학습 시작...\n",
      "WARNING:accelerate.utils.other:Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 학습 하이퍼파라미터 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./fine-tuned-models/olmo-7b-finetuned\",\n",
    "    eval_strategy=\"steps\",  # evaluation_strategy 대신 eval_strategy 사용\n",
    "    eval_steps=500,\n",
    "    learning_rate=5e-5,  # 조정된 학습률\n",
    "    per_device_train_batch_size=4,  # GPU 메모리에 맞게 조정\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=8,  # 더 적은 배치 크기를 보완\n",
    "    num_train_epochs=3,  # 에폭 수 감소\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    fp16=False,\n",
    "    bf16=True,  # bfloat16 정밀도 사용\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.1,  # 워밍업 스텝 추가\n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.999,\n",
    "    load_best_model_at_end=True,  # 최고 성능 모델 로드\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    report_to=\"none\",  # tensorboard 제거, 로깅 비활성화\n",
    ")\n",
    "\n",
    "# 데이터 콜레이터 초기화\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "# 체크포인트 경로 설정\n",
    "checkpoint_dir = \"./fine-tuned-models/checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# 트레이너 초기화 및 학습\n",
    "logger.info(\"트레이너 초기화 및 학습 시작...\")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6912' max='6912' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6912/6912 5:48:46, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.177400</td>\n",
       "      <td>1.170737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.101300</td>\n",
       "      <td>1.103282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.982200</td>\n",
       "      <td>0.999830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.907000</td>\n",
       "      <td>0.908222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.700700</td>\n",
       "      <td>0.825963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.643900</td>\n",
       "      <td>0.753480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.571200</td>\n",
       "      <td>0.656761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.480700</td>\n",
       "      <td>0.552197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.396000</td>\n",
       "      <td>0.445913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.201400</td>\n",
       "      <td>0.412890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.190800</td>\n",
       "      <td>0.390684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.187000</td>\n",
       "      <td>0.380609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.186600</td>\n",
       "      <td>0.379047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:최종 모델 저장 중: ./fine-tuned-models/fine-tuned-olmo7B-v12-80000\n",
      "INFO:__main__:파인튜닝 완료!\n"
     ]
    }
   ],
   "source": [
    "# 학습 실행\n",
    "trainer.train()\n",
    "\n",
    "# 최종 모델 및 토크나이저 저장\n",
    "final_model_path = \"./fine-tuned-models/fine-tuned-olmo7B-v12-80000\"\n",
    "logger.info(f\"최종 모델 저장 중: {final_model_path}\")\n",
    "model.save_pretrained(final_model_path)\n",
    "tokenizer.save_pretrained(final_model_path)\n",
    "logger.info(\"파인튜닝 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 모델 테스트\n",
    "def test_model(prompt):\n",
    "    inputs = tokenizer(f\"Input: {prompt}\\nOutput: \", return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_new_tokens=300,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "        )\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:프롬프트: 오늘 하루 어땠니?. Generally when this conversation happeneing? And what should I reply?\n",
      "INFO:__main__:응답: Input: 오늘 하루 어땠니?. Generally when this conversation happeneing? And what should I reply?\n",
      "Output: The image depicts a young woman with dark hair, wearing a white shirt, standing in front of a window. The purpose of the image is to showcase the woman's appearance and surroundings.\n",
      "\n",
      "* A young woman with dark hair:\n",
      "\t+ Her hair is styled in a neat and tidy manner.\n",
      "\t+ She has a subtle smile on her face.\n",
      "* She is wearing a white shirt:\n",
      "\t+ The shirt appears to be a casual, relaxed fit.\n",
      "\t+ It may be made of cotton or another lightweight material.\n",
      "* There is a window behind her:\n",
      "\t+ The window is large and lets in plenty of natural light.\n",
      "\t+ It provides a glimpse into the outside world.\n",
      "\n",
      "Overall, the image presents a serene and peaceful scene, with the woman's gentle smile and relaxed posture adding to the sense of calmness.\n",
      "Output: 되냐 그걸로 하면 다니까 그냥��100 오늘 뭐하는 날인데나 아니면��네 최소한 인간으로서의 예인은\n",
      "Output: The image features a young woman with long, straight black hair and bangs, wearing a white shirt. The\n",
      "\n",
      "\n",
      "INFO:__main__:프롬프트: 안녕 내 이름은 준이야. Generally when this conversation happeneing?  And what should I reply?\n",
      "INFO:__main__:응답: Input: 안녕 내 이름은 준이야. Generally when this conversation happeneing?  And what should I reply?\n",
      "Output: The image shows a screenshot from a TV show or movie, featuring three women sitting at a table with food in front of them. The purpose of the image is to capture a moment from the story being told.\n",
      "\n",
      "* Three women are sitting at a table:\n",
      "\t+ They appear to be eating or preparing to eat.\n",
      "\t+ Their facial expressions suggest they are engaged in conversation or discussion.\n",
      "* A plate of food is on the table:\n",
      "\t+ It appears to be some kind of snack or appetizer.\n",
      "\t+ The food is likely a part of the meal being shared among the three women.\n",
      "\n",
      "Overall, the image suggests that the three women are having a casual conversation or gathering, possibly over a snack or while enjoying a meal together.. 2 따다 니 이쪽 할게요 으 으 아� 우리 타임이 좀 있어고 하지만\n",
      "Output: This image features a screenshot from a TV show or movie, showcasing three women seated at a table with food in front of them.\n",
      "\n",
      "In the foreground, the woman on the left has blonde hair and is wearing a white hoodie. She appears to be speaking to her companions, who are both dressed in casual attire. The table is set with various dishes, including what looks like kimchi, rice,\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 테스트 예시\n",
    "test_prompts = [\"오늘 하루 어땠니?. Generally when this conversation happeneing? And what should I reply?\", \"안녕 내 이름은 준이야. Generally when this conversation happeneing?  And what should I reply?\"]\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    logger.info(f\"프롬프트: {prompt}\")\n",
    "    logger.info(f\"응답: {test_model(prompt)}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
